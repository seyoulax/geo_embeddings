{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787dd8f4-3074-46f4-8031-88e212b02efe",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5d090-07c9-42ae-8152-ecb65430a688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import wandb\n",
    "import pickle\n",
    "import optuna\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch_geometric import seed_everything\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../src\")\n",
    "\n",
    "from models import InductiveGATwithIMGS, InductiveGCNwithIMGS, CNNBlock\n",
    "from utils import set_seed, EarlyStoppingR2, train_CFG\n",
    "from training_utils import train_inductive, inference_inductive, cross_val_inductive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee6c452-edc0-422b-9791-60e29e4d944c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global params\n",
    "\n",
    "#IMPORTANT: USE THIS SEED\n",
    "SEED = 111\n",
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")\n",
    "\n",
    "# use feature-propagation algo or not\n",
    "use_features_propagation = False\n",
    "\n",
    "# current region that you are working on\n",
    "region = 812\n",
    "\n",
    "regions_mapper = {\n",
    "        777 : \"Moscow\",\n",
    "        812 : \"Saint-Petersburg\",\n",
    "        287 : \"Kazan\",\n",
    "        473 : \"Sochi\"\n",
    "    }\n",
    "\n",
    "\n",
    "#paths params\n",
    "# path_for_graph = f\"../../../data/graph_preprocessing/{regions_mapper[region]}/graph_with_cv_full.pickle\"\n",
    "path_for_graph = f\"/home/jupyter/datasphere/s3/s3-sirius/sirius_2024_participants/twwist/graph_with_cv_full_and_images/images_graph_{region}.pickle\"\n",
    "checkpoints_path = \"../../chkps/inductive_gcn_pipeline\" #from the notebook directory, must start with ../../chkps/\n",
    "assert (os.path.exists(checkpoints_path)), \"path for checkoints must exists\"\n",
    "\n",
    "\n",
    "#model params\n",
    "hidden_dim = 64\n",
    "n_layers = 4\n",
    "n_head=2\n",
    "cnn_out_channels=64\n",
    "\n",
    "#training params setting\n",
    "optimizer_name = \"AdamW\" #(\"Adam\", \"AdamW\", \"RMSProp\")\n",
    "use_scheduler = True\n",
    "\n",
    "#early stopper params\n",
    "use_stopper = True\n",
    "stopper_patience = 100\n",
    "stopper_delta = 0.001\n",
    "\n",
    "verbose = 10\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "#number of epochs before starting using sheduler and stopper\n",
    "started_patience = 1\n",
    "\n",
    "#image features\n",
    "add_image_features = True\n",
    "\n",
    "image_features_path = f\"../../data/image_embeddings/image_features_{region}.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9d1dd-b039-4ff3-85e9-0a6519f46bce",
   "metadata": {},
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df8cdd-55ae-4544-b1fc-ee3ffb617425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph = torch.load(\n",
    "    path_for_graph\n",
    ").to(device, \"x\", \"edge_index\")\n",
    "\n",
    "if use_features_propagation:\n",
    "    graph.x[graph.x == -1] = torch.nan\n",
    "    graph = T.FeaturePropagation(missing_mask=torch.isnan(graph.x), num_iterations = 400)(graph)\n",
    "    \n",
    "if add_image_features:\n",
    "    image_features = torch.load(image_features_path)\n",
    "    graph.x = torch.cat([graph.x, image_features], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679b1bc-cb4b-40ac-8a25-28f1707ea438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#setting up dataloaders for default training\n",
    "loader_batch_size=256\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    graph,\n",
    "    input_nodes=graph.train_mask,\n",
    "    num_neighbors=[-1, -1, -1, -1],\n",
    "    batch_size=loader_batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "#val loader\n",
    "val_loader = NeighborLoader(\n",
    "    graph,\n",
    "    input_nodes=graph.val_mask,\n",
    "    num_neighbors=[-1, -1, -1, -1],\n",
    "    batch_size=loader_batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "#special loader for efficient inferencing\n",
    "inference_loader = NeighborLoader(\n",
    "    graph,\n",
    "    input_nodes=None,\n",
    "    num_neighbors=[-1],\n",
    "    batch_size=4056,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561383fc-08e4-4b65-ba2d-2681100362e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce249bc-3f4c-47cd-aa78-646f08141893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "\n",
    "# model\n",
    "# can be InductiveGCNwithIMGS or InductiveGATwithIMGS\n",
    "# InductiveGATwithIMGS will require one more param - head (number of heads in each conv)\n",
    "\n",
    "model = InductiveGCNwithIMGS(\n",
    "    n_in=graph.num_features,\n",
    "    n_out=1,\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_layers=n_layers,\n",
    "    cnn_in_channels=graph.imgs[0].shape[0], \n",
    "    cnn_out_channels=cnn_out_channels,\n",
    ").to(device)\n",
    "\n",
    "#optimizer\n",
    "optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=0.001771619056705244)\n",
    "\n",
    "#scheduler\n",
    "if use_scheduler:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer=optimizer, factor=0.7, patience=30, threshold=0.01, min_lr=1e-5 / 5\n",
    "    )\n",
    "\n",
    "#loss function \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#EarlyStopper\n",
    "if use_stopper:\n",
    "    earlystopper = EarlyStoppingR2(\n",
    "        patience=stopper_patience,\n",
    "        verbose=False,\n",
    "        delta=stopper_delta,\n",
    "        path=checkpoints_path,\n",
    "        trace_func=print,\n",
    "        model_name=\"best_model_train.pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b593a-33f4-4360-939e-edd6096a95fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading pretrained model\n",
    "pretrained_model =  timm.create_model('resnet18', pretrained=True, in_chans=12, num_classes=0).to(device)\n",
    "use_pretrained = False\n",
    "\n",
    "if base_train := True:\n",
    "\n",
    "    #base train\n",
    "    train_cfg = train_CFG()\n",
    "    train_cfg(\"num_epochs\", 100)\n",
    "    train_cfg(\"verbose\", 1)\n",
    "    train_cfg(\"scheduler\", True)\n",
    "    \n",
    "    train_inductive(\n",
    "        train_loader=train_loader, \n",
    "        val_loader=val_loader, \n",
    "        model=model, \n",
    "        optimizer=optimizer, \n",
    "        loss_fn=loss_fn, \n",
    "        train_cfg=train_cfg, \n",
    "        scheduler=(scheduler if use_scheduler else None),\n",
    "        started_patience=started_patience,\n",
    "        earlystopper=(earlystopper if use_stopper else None),\n",
    "        use_pretrained=use_pretrained,\n",
    "        pretrained_model=pretrained_model\n",
    "    )\n",
    "    \n",
    "    #evaluation\n",
    "    metrics = inference(dataset, model, inference_loader)\n",
    "\n",
    "print(\"Eval metrics: \")\n",
    "print(f'Train R2: {metrics[0]}\\n'\n",
    "       f'Val R2: {metrics[1]}\\n'\n",
    "       f'Test R2: {metrics[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654aaf1-fe75-4f72-a797-9025dea18776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = inference_inductive(graph, model, inference_loader, use_pretrained=use_pretrained, pretrained_model=pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b2977-7b37-4f93-bbe8-5111e5d09511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Train R2: {metrics[0]}\\n'\n",
    "       f'Val R2: {metrics[1]}\\n'\n",
    "       f'Test R2: {metrics[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9abf273-db77-43c6-ad28-6c5821ee92ac",
   "metadata": {},
   "source": [
    "# Cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969afbfc-43f4-4ed5-8063-984a26421bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_model =  timm.create_model('resnet18', pretrained=True, in_chans=12, num_classes=0).to(device)\n",
    "use_pretrained = False\n",
    "\n",
    "if cv := True:\n",
    "\n",
    "    cv_cfg = train_CFG()\n",
    "    cv_cfg(\"num_epochs\", num_epochs)\n",
    "    cv_cfg(\"verbose\", verbose)\n",
    "    cv_cfg(\"scheduler\", (True if use_scheduler else None))\n",
    "    cv_cfg(\"stopper_patience\", stopper_patience)\n",
    "    cv_cfg(\"stopper_delta\", stopper_delta)\n",
    "    cv_cfg(\"started_patience\", started_patience)\n",
    "    \n",
    "    model_params = dict(\n",
    "        n_in=graph.num_features,\n",
    "        n_out=1,\n",
    "        hidden_dim=hidden_dim,\n",
    "        n_layers=n_layers,\n",
    "        head=n_head, #depending on model architecture you`d like to use heads \n",
    "        cnn_in_channels=graph.imgs[0].shape[0], \n",
    "        cnn_out_channels=cnn_out_channels,\n",
    "    )\n",
    "\n",
    "\n",
    "    val_score = cross_val_inductive(\n",
    "        num_folds=5, \n",
    "        dataset=graph, \n",
    "        model_name=\"GAT\", #model architecture name\n",
    "        model_params=model_params,\n",
    "        optimizer_params={\"lr\" : 0.001771619056705244}, \n",
    "        optimizer_name=optimizer_name,\n",
    "        cv_cfg=cv_cfg, \n",
    "        checkpoints_path=\"../../chkps/inductive_gcn_cv_pipeline\", # checkpoints path\n",
    "        eval_test=False, # For now if set to \"True\" than all models evaluates using \"test_mask\" from graph\n",
    "        device=device,\n",
    "        use_pretrained=use_pretrained,\n",
    "        pretrained_model=pretrained_model\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e9976-9a47-4ee0-bb2c-69fc3560bced",
   "metadata": {},
   "source": [
    "|                                   | **GAT** |          | **GCN** |          |\n",
    "|-----------------------------------|---------|----------|---------|----------|\n",
    "| **without images**                | 0.461   |          | 0.494   |          |\n",
    "| **basic CNN**                     | 0.452   |          | 0.311   |          |\n",
    "| **pretrained efficient net**      | 0.376   |          | 0.357   |          |\n",
    "| **pretrained efficient net with image features** | 0.416   |          | 0.450   |          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceccd9c-a1f2-4a6e-b58e-1d009cdf2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo/chkps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
